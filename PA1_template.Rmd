---
title: "Reproducible Research: Peer Assessment 1"
author: "Kenneth Dombrowski"
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: true
---

Text in italics is copied from the [assignment][1] for reference.

These global options will cause R code to always echo by default, nothing to be 
cached, and for Rmarkdown to be verbose:

```{r opts-knit}
library(knitr)
opts_knit$set(echo = TRUE, cache = FALSE, verbose = TRUE)
```

## Loading and preprocessing the data

To load the data your working directory must be set to the top level of this 
repo, e.g. `setwd("~/git/RepData_PeerAssessment1")`.

```{r load-data}
unzip("activity.zip")
activity = read.csv("activity.csv")
```

The data consists of one observation taken every five minutes for a period of 
two months, or 61 days (October 1...31 + November 1...30).  61 * 1440 (minutes 
in a day) = 87,840, divided by 5 we expect 17,568 observations.

1440 / 5 works out to 288 observations per day.

```{r summarize-data}
str(activity)
summary(activity)
```

Notice the 2,304 `NA` values out of 17,568 observations (about 13%).


###  Non-contiguous intervals

The summary of the `interval` variable is interesting in that the max value is 
greater than the total number of minutes in a day.  From the `str()` output one 
might expect the values to be a series from 0 to 1435 (288 increments of 5), so
you could do math like `as.POSIXct(activity[288, 2]) + (60 * activity[288, 3])`
and get the result `"2012-10-01 23:55:00 EDT"`.

Instead, the `interval` value uses the 10s place to indicate the hour; for midnight 
to one a.m., the range 0..55 is used, one a.m. to two a.m. uses 100..155, eleven p.m.
to midnight uses 2300..2355.

Rather than trying to parse that, create a new variable to represent the minute 
of the day by assigning a vector of 288 increments of 5, beginning with 0, which 
will repeat for each day's 288 observations:

```{r add-dayminute}
activity$dayminute <- c(0:287) * 5
tail(activity)
```

With `dayminute` in place, we can use it in combination with the `date` string 
to add a datetime variable, called `dt`:

```{r add-dt}
activity$dt <- as.POSIXct(activity[, 2]) + (60 * activity[, 4])
tail(activity)
```


## What is mean total number of steps taken per day?

*For this part of the assignment, you can ignore the missing values in the dataset.*

First, we create an aggregate of the sum of all steps taken each day:

```{r total-steps-per-day}
steps_per_day <- aggregate(steps ~ date, activity, sum)
```

Again, let's take a peek at the data to make sure it looks like what we expect:

```{r total-steps-per-day-summary}
str(steps_per_day)
head(steps_per_day)
summary(steps_per_day)
```

Notice we have only 53 observations, but the `date` factor has the expected 61 
levels (31 days in October + 30 days in November).  This suggests there are 8 
dates for which we have only `NA` values.

To test this theory, let's subset only the `NA` rows of the activity data and 
turn it into a boolean:

```{r na-steps-per-day}
na_steps <- subset(activity, is.na(activity$steps), c("date", "steps"))
na_steps$steps <- TRUE
aggregate(steps ~ date, na_steps, sum)
```

There are only 8 days with `NA` steps values, and all 8 are missing all 288 
observations for the day.


### Histogram of total steps per day

*Make a histogram of the total number of steps taken each day*

The histogram displays the frequency that occurances of the total steps taken per
day falls within a set of ranges.

Adding a `breaks` argument to increase the granularity of the graph reveals some
interesting sparse ranges toward the extremes of the x-axis:

```{r total-steps-per-day-histogram}
hist(steps_per_day$steps, main = "Total steps per day", xlab = "Number of steps", 
     breaks = 36, col = "darkorange")
```


### Mean & median of total steps per day

*Calculate and report the mean and median of the total number of steps taken per day*

```{r mean-and-median-total-steps-per-day}
mean_steps_per_day <- mean(steps_per_day$steps)
median_steps_per_day <- median(steps_per_day$steps)
```

The mean steps per day is **`r mean_steps_per_day`**, and the median is **`r median_steps_per_day`**.


## What is the average daily activity pattern?

This time our aggregate is the average steps taken during each interval, 
across all days in the dataset.

```{r avg-steps-per-interval}
avg_steps_per_interval <- aggregate(steps ~ interval, activity, mean)
head(avg_steps_per_interval)
summary(avg_steps_per_interval)
```


### Time-series plot of daily activity pattern

*Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)*

```{r avg-steps-per-interval-time-series-plot}
plot(avg_steps_per_interval$interval, avg_steps_per_interval$steps, type = "l",
     main = "Daily activity pattern", xlab = "interval", ylab = "avg. steps taken")
# add grid depicting 24 hours
grid(nx = 24, ny = 1)
```


### Interval with most steps on average

*Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?*

```{r interval-with-most-steps-on-avg}
# convert from list to data.frame
avg_steps_per_interval_df = as.data.frame(avg_steps_per_interval)
# sort by avg steps
avg_steps_per_interval_df[ order(avg_steps_per_interval_df[2], decreasing = TRUE),  ][1, ]
interval_with_highest_avg_steps <- avg_steps_per_interval_df[ order(avg_steps_per_interval_df[2], decreasing = TRUE),  ][1, 1]
```

The interval with the most steps on average is **`r interval_with_highest_avg_steps`**.


## Imputing missing values

*Note that there are a number of days/intervals where there are missing values (coded as NA). The presence of missing days may introduce bias into some calculations or summaries of the data.*

### Count missing values in the dataset

*Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)*

```{r count-nas}
count_na_steps <- nrow(subset(activity, is.na(activity$steps)))
```

There are **`r count_na_steps`** rows with `NA` values.


### Strategy for filling in missing data

*Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.*


### Create new dataset with missing values filled in

*Create a new dataset that is equal to the original dataset but with the missing data filled in.*


### Compare new dataset with original

*Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?*






## Are there differences in activity patterns between weekdays and weekends?

*For this part the weekdays() function may be of some help here. Use the dataset with the filled-in missing values for this part.*

### Add factor variable to indicate weekday or weekend

*Create a new factor variable in the dataset with two levels – “weekday” and “weekend” indicating whether a given date is a weekday or weekend day.*



### Create panel plot comparing time series of weekday data vs. weekend data

*Make a panel plot containing a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). See the README file in the GitHub repository to see an example of what this plot should look like using simulated data.*





[1]: https://class.coursera.org/repdata-032/human_grading/view/courses/975145/assessments/3/submissions
[2]: http://stackoverflow.com/questions/26001534/maintain-nas-after-aggregation-r?rq=1
